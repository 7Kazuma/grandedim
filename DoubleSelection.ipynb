{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Double Selection and sample-splitting, simulations\n",
    "### Used in Section 2.2 of the HDMetrics class.\n",
    "### Jeremy L Hour\n",
    "### 04/01/2018\n",
    "### Edited: 28/02/2018\n",
    "\n",
    "rm(list=ls())\n",
    "set.seed(999)\n",
    "\n",
    "### 0. Settings\n",
    "\n",
    "### Load packages\n",
    "library(\"ggplot2\")\n",
    "library(\"gridExtra\")\n",
    "library(\"MASS\")\n",
    "\n",
    "### Load user-defined functions\n",
    "source(\"functions/DataSim.R\") \n",
    "source(\"functions/LassoFISTA.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simulation parameters\n",
    "R = 1000 # nb simulations\n",
    "n = 200 # sample size\n",
    "p = 150 # nb variables\n",
    "K = 5 # nb folds\n",
    "a = .5 # ATT\n",
    "\n",
    "split = runif(n)\n",
    "cvgroup = as.numeric(cut(split,quantile(split,probs = seq(0, 1, 1/K)),include.lowest = T))  \n",
    "\n",
    "g = .1/log(max(p,n))\n",
    "lambda = 2.2*qnorm(1-.5*g/p)/sqrt(n) # Lasso penalty level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = matrix(ncol=3, nrow=R)\n",
    "stdev = vector(length=R)\n",
    "t_start = Sys.time()\n",
    "\n",
    "for(r in 1:R){\n",
    "  ### GENERATE DATA\n",
    "  data = DataSim(n=n,p=p,Ry=.3,Rd=.7)\n",
    "  X = data$X; y = data$y; d = data$d\n",
    "  \n",
    "  ### METHOD 1: Naive selection\n",
    "  lassoselec = LassoFISTA(y=y,X=cbind(d,X),nopen=c(1,2),lambda=lambda) # Do not penalize the constant\n",
    "  Snaive = which(lassoselec$beta != 0)\n",
    "  Snaive = Snaive[!Snaive %in% c(1,2)] # delete intercept and treatment variable\n",
    "  if(length(Snaive)==0){\n",
    "    naivefit = lm(y ~ d)\n",
    "  } else {\n",
    "    naivefit = lm(y ~ d + X[,Snaive])\n",
    "  }\n",
    "  \n",
    "  ### METHOD 2: Double-Selection, no sample-splitting\n",
    "  # A. Selection on Treatment\n",
    "  treatfit = LassoFISTA(y=d,X=X,nopen=c(1),lambda=.15*lambda) # Do not penalize the constant\n",
    "  Sd = which(treatfit$beta != 0)\n",
    "  Sd = Sd[!Sd == 1] # delete intercept\n",
    "  \n",
    "  # B. Selection on Outcome\n",
    "  outcomefit = LassoFISTA(y=y,X=X,nopen=c(1),lambda=lambda) # Do not penalize the constant\n",
    "  Sy = which(outcomefit$beta != 0)\n",
    "  Sy = Sy[!Sy == 1] # delete intercept\n",
    "  \n",
    "  # C. Compute Post-Double-Selection\n",
    "  Shat = union(Sy,Sd)\n",
    "  if(length(Shat)==0){\n",
    "    DSfit = lm(y ~ d)\n",
    "  } else {\n",
    "    DSfit = lm(y ~ d + X[,Shat])\n",
    "  }\n",
    "  \n",
    "  # D. Compute sd\n",
    "  if(length(Shat)==0){\n",
    "    treatfit = lm(d ~ 1)\n",
    "  } else {\n",
    "    treatfit = lm(d ~ X[,Shat])\n",
    "  }\n",
    "  sigmaNum = sum(treatfit$residuals^2*DSfit$residuals^2) /(n - length(Shat) - 1)\n",
    "  sigmaDenom = sum(treatfit$residuals^2) / n\n",
    "  stdev[r] = sqrt( sigmaNum / sigmaDenom^2) / sqrt(n)\n",
    "  \n",
    "  \n",
    "  ### METHOD 3: Double Selection with Sample Splitting\n",
    "  theta = vector(length=K)\n",
    "  for(k in 1:K){\n",
    "    Ik = cvgroup==k # Separate the sample\n",
    "    NIk = cvgroup!=k\n",
    "    \n",
    "    # 0. Adjust Lasso penalty level\n",
    "    gstar = .1/log(max(p,sum(NIk)))\n",
    "    lambdastar = 2.2*qnorm(1-.5*g/p)/sqrt(sum(NIk)) # Lasso penalty level\n",
    "    \n",
    "    # Abis. Selection on Treatment\n",
    "    treatfit = LassoFISTA(y=d[NIk],X=X[NIk,],nopen=c(1),lambda=.15*lambdastar) # Do not penalize the constant\n",
    "    Sd = which(treatfit$beta != 0)\n",
    "    Sd = Sd[!Sd == 1] # delete intercept\n",
    "    \n",
    "    # Bbis. Selection on Outcome\n",
    "    outcomefit = LassoFISTA(y=y[NIk],X=X[NIk,],nopen=c(1),lambda=lambdastar) # Do not penalize the constant\n",
    "    Sy = which(outcomefit$beta != 0)\n",
    "    Sy = Sy[!Sy == 1] # delete intercept\n",
    "    \n",
    "    # Cbis. Compute Post-Double-Selection\n",
    "    Shat = union(Sy,Sd)\n",
    "    if(length(Shat)==0){\n",
    "      outcomePL = lm(y[NIk] ~ 1)\n",
    "      treatPL = lm(d[NIk] ~ 1)\n",
    "    } else {\n",
    "      outcomePL = lm(y[NIk] ~ X[NIk,Shat])\n",
    "      treatPL = lm(d[NIk] ~ X[NIk,Shat])\n",
    "    }\n",
    "    \n",
    "    # D. Target param on left-out sample\n",
    "    ytilde = y[Ik] - cbind(rep(1,sum(Ik)),X[Ik,Shat])%*%coef(outcomePL)\n",
    "    dtilde = d[Ik] - cbind(rep(1,sum(Ik)),X[Ik,Shat])%*%coef(treatPL)\n",
    "    Ikfit = lm(ytilde ~ dtilde)\n",
    "    \n",
    "    theta[k] = Ikfit$coef['dtilde']\n",
    "  }\n",
    "  \n",
    "  \n",
    "  ### COLLECTING RESULTS\n",
    "  Results[r,] = c(naivefit$coef['d'],\n",
    "                  DSfit$coef['d'],\n",
    "                  mean(theta))\n",
    "}\n",
    "\n",
    "print(Sys.time()-t_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
