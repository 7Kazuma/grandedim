{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n",
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n",
      "Loading required package: Matrix\n",
      "Loading required package: foreach\n",
      "Loaded glmnet 2.0-18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Double Selection et Sample-splitting, simulations\n",
    "### Jeremy L Hour\n",
    "### 04/01/2018\n",
    "### Edited: 30/09/2018\n",
    "\n",
    "rm(list=ls())\n",
    "set.seed(999)\n",
    "\n",
    "### 0. Settings\n",
    "\n",
    "### Load packages\n",
    "library(\"ggplot2\")\n",
    "library(\"gridExtra\")\n",
    "library(\"glmnet\")\n",
    "library(\"MASS\")\n",
    "\n",
    "### Load user-defined functions\n",
    "source(\"functions/DataSim.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simulation parameters\n",
    "R = 1000 # nb simulations\n",
    "n = 200 # sample size\n",
    "p = 150 # nb variables\n",
    "K = 5 # nb folds\n",
    "tau = .5 # ATT\n",
    "\n",
    "split = runif(n)\n",
    "cvgroup = as.numeric(cut(split,quantile(split,probs = seq(0, 1, 1/K)),include.lowest = T))  \n",
    "\n",
    "g = .1/log(max(p,n))\n",
    "lambda = 2.2*qnorm(1-.5*g/p)/sqrt(n) # Lasso penalty level (Theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in c * gamma:\n",
      "“Recycling array of length 1 in array-vector arithmetic is deprecated.\n",
      "  Use c() or as.vector() instead.\n",
      "”Warning message in c * b:\n",
      "“Recycling array of length 1 in array-vector arithmetic is deprecated.\n",
      "  Use c() or as.vector() instead.\n",
      "”"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in mvrnorm(n = n, mu = rep(0, p), Sigma): 'Sigma' is not positive definite\n",
     "output_type": "error",
     "traceback": [
      "Error in mvrnorm(n = n, mu = rep(0, p), Sigma): 'Sigma' is not positive definite\nTraceback:\n",
      "1. DataSim(n = n, p = p, Ry = 0.3, Rd = 0.7)",
      "2. mvrnorm(n = n, mu = rep(0, p), Sigma)",
      "3. stop(\"'Sigma' is not positive definite\")"
     ]
    }
   ],
   "source": [
    "Results = matrix(ncol=3, nrow=R)\n",
    "stdev = vector(length=R)\n",
    "t_start = Sys.time()\n",
    "\n",
    "for(r in 1:R){\n",
    "  ### GENERATION DES DONNEES\n",
    "  data = DataSim(n=n,p=p,Ry=.3,Rd=.7,Intercept=F,a=tau)\n",
    "  X = data$X; y = data$y; d = data$d\n",
    "  \n",
    "  ### METHOD 1: Selection naive\n",
    "  phi = rep(1,p+1); phi[1] = 0 # Do not penalize \"d\"\n",
    "  lasso.selec = glmnet(cbind(d,X),y, family=\"gaussian\",alpha=1,penalty.factor=phi,lambda=lambda)\n",
    "  b.lasso = coef(lasso.selec); b.lasso = b.lasso[-c(1,2)] # on enleve la constante et la variable de traitement\n",
    "  s.hat = which(b.lasso != 0)\n",
    "  if(length(s.hat)==0){\n",
    "    naive.fit = lm(y ~ d)\n",
    "  } else {\n",
    "    naive.fit = lm(y ~ d + X[,s.hat])\n",
    "  }\n",
    "  \n",
    "  ### METHOD 2: Double-Selection, no sample-splitting\n",
    "  # A. Selection sur le Traitement\n",
    "  treat.selec = glmnet(X,d, family=\"gaussian\",alpha=1,lambda=.15*lambda)\n",
    "  b.treat = coef(treat.selec); b.treat = b.treat[-1] # on enleve la constante\n",
    "  S.d = which(b.treat != 0)\n",
    "  \n",
    "  # B. Selection sur l'Outcome\n",
    "  outcome.selec = glmnet(X,y, family=\"gaussian\",alpha=1,lambda=lambda)\n",
    "  b.outcome = coef(outcome.selec); b.outcome = b.outcome[-1] # on enleve la constante\n",
    "  S.y = which(b.outcome != 0)\n",
    "  \n",
    "  # C. Calcul de l'estimateur de double selection\n",
    "  s.hat = union(S.y,S.d)\n",
    "  if(length(s.hat)==0){\n",
    "    DS.fit = lm(y ~ d)\n",
    "  } else {\n",
    "    DS.fit = lm(y ~ d + X[,s.hat])\n",
    "  }\n",
    "  \n",
    "  # D. Compute sd\n",
    "  if(length(s.hat)==0){\n",
    "    treat.fit = lm(d ~ 1)\n",
    "  } else {\n",
    "    treat.fit = lm(d ~ X[,s.hat])\n",
    "  }\n",
    "  sigmaNum = sum(treat.fit$residuals^2*DS.fit$residuals^2) /(n - length(s.hat) - 1)\n",
    "  sigmaDenom = sum(treat.fit$residuals^2) / n\n",
    "  stdev[r] = sqrt( sigmaNum / sigmaDenom^2) / sqrt(n)\n",
    "  \n",
    "  \n",
    "  ### METHOD 3: Double selection et sample-splitting\n",
    "  theta = vector(length=K)\n",
    "  for(k in 1:K){\n",
    "    Ik = cvgroup==k # separer les donnees\n",
    "    NIk = cvgroup!=k\n",
    "    \n",
    "    # 0. Ajustement du lambda\n",
    "    gstar = .1/log(max(p,sum(NIk)))\n",
    "    lambdastar = 2.2*qnorm(1-.5*g/p)/sqrt(sum(NIk)) # Lasso penalty level\n",
    "    \n",
    "    # Abis. Selection sur le traitement\n",
    "    treat.selec = glmnet(X[NIk,],d[NIk], family=\"gaussian\",alpha=1,lambda=.15*lambdastar)\n",
    "    b.treat = coef(treat.selec); b.treat = b.treat[-1] # on enleve la constante\n",
    "    S.d = which(b.treat != 0)  \n",
    "    \n",
    "    # Bbis. Selection on Outcome\n",
    "    outcome.selec = glmnet(X[NIk,],y[NIk], family=\"gaussian\",alpha=1,lambda=lambdastar)\n",
    "    b.outcome = coef(outcome.selec); b.outcome = b.outcome[-1] # on enleve la constante\n",
    "    S.y = which(b.outcome != 0)\n",
    "    \n",
    "    # Cbis. Compute Post-Double-Selection\n",
    "    s.hat = union(S.y,S.d)\n",
    "    if(length(s.hat)==0){\n",
    "      outcomePL = lm(y[NIk] ~ 1)\n",
    "      treatPL = lm(d[NIk] ~ 1)\n",
    "    } else {\n",
    "      outcomePL = lm(y[NIk] ~ X[NIk,s.hat])\n",
    "      treatPL = lm(d[NIk] ~ X[NIk,s.hat])\n",
    "    }\n",
    "    \n",
    "    # D. Target param on left-out sample\n",
    "    ytilde = y[Ik] - cbind(rep(1,sum(Ik)),X[Ik,s.hat])%*%coef(outcomePL)\n",
    "    dtilde = d[Ik] - cbind(rep(1,sum(Ik)),X[Ik,s.hat])%*%coef(treatPL)\n",
    "    Ikfit = lm(ytilde ~ dtilde)\n",
    "    \n",
    "    theta[k] = Ikfit$coef['dtilde']\n",
    "  }\n",
    "  \n",
    "  \n",
    "  ### COLLECTING RESULTS\n",
    "  Results[r,] = c(naive.fit$coef['d'],\n",
    "                  DS.fit$coef['d'],\n",
    "                  mean(theta))\n",
    "}\n",
    "\n",
    "print(Sys.time()-t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        bias RMSE\n",
      "Naive                     NA   NA\n",
      "Immunized                 NA   NA\n",
      "Immunized, Cross-fitted   NA   NA\n"
     ]
    }
   ],
   "source": [
    "### COMPUTE BIAS AND RMSE\n",
    "StatDisplay = data.frame()\n",
    "StatDisplay[1:3,\"bias\"] = apply(Results-a,2,mean)\n",
    "StatDisplay[1:3,\"RMSE\"] = sqrt(apply((Results-a)^2,2,mean))\n",
    "row.names(StatDisplay) = c(\"Naive\",\"Immunized\",\"Immunized, Cross-fitted\")\n",
    "print(StatDisplay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DRAW CHARTS\n",
    "id = c(mapply(function(x) rep(x,R),1:3))\n",
    "val = c(Results)-a\n",
    "data_res = data.frame(val = val, model = id)\n",
    "\n",
    "M = max(abs(quantile(Results,.01,na.rm=T)),abs(quantile(Results,.99,na.rm=T)))\n",
    "lb = -1.1*M; ub = 1.1*M\n",
    "\n",
    "get.plot <- function(data,modelS,title=\"A Title\",s){\n",
    "  plot_res <- ggplot(subset(data, (model==modelS)), aes(x=val)) + \n",
    "    geom_histogram(binwidth = .02, alpha=.5, position='identity',fill=\"steelblue\", aes(y = ..density..)) +\n",
    "    scale_x_continuous(limits=c(lb,ub), name=\"Treatment effect\") +\n",
    "    ggtitle(title) + \n",
    "    stat_function(fun = dnorm, args=list(mean=0, sd=s), colour=\"darkorchid3\", size=1) +\n",
    "    theme(plot.title = element_text(lineheight=.8, face=\"bold\"),legend.position=\"none\")\n",
    "  return(plot_res)\n",
    "} # plot func\n",
    "\n",
    "pdf(\"plots/Immunized.pdf\",width=14,height=4)\n",
    "grid.arrange(get.plot(data_res,1,\"Naive Post-Selec\", mean(stdev)), get.plot(data_res,2,\"Double-Selec\", mean(stdev)), get.plot(data_res,3,\"Double-Selec, Cross-fitting\", mean(stdev)), ncol=3)\n",
    "dev.off()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
